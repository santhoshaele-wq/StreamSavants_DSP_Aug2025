{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "001617fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6438df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING\n",
      "================================================================================\n",
      "Starting dataset shape: (57281, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "path = \"../data/raw/synthetic_stroke_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Basic preprocessing\n",
    "df = df[df['gender'] != 'Other'].reset_index(drop=True)\n",
    "df['bmi'].fillna(df['bmi'].median(), inplace=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Starting dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5653d04",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48332fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created age_group feature\n",
      "Created high_risk_score feature\n",
      "Created glucose_level_cat feature\n",
      "Created bmi_category feature\n",
      "Created smoking_risk feature\n",
      "\n",
      "Dataset shape after feature engineering: (57281, 17)\n"
     ]
    }
   ],
   "source": [
    "df_processed = df.copy()\n",
    "\n",
    "# Create age groups\n",
    "df_processed['age_group'] = pd.cut(df_processed['age'], \n",
    "                                    bins=[0, 30, 40, 50, 60, 100], \n",
    "                                    labels=['<30', '30-40', '40-50', '50-60', '60+'])\n",
    "print(\"Created age_group feature\")\n",
    "\n",
    "# Create high risk score\n",
    "df_processed['high_risk_score'] = (df_processed['hypertension'] + \n",
    "                                    df_processed['heart_disease'] + \n",
    "                                    (df_processed['age'] > 50).astype(int) +\n",
    "                                    (df_processed['avg_glucose_level'] > 150).astype(int))\n",
    "print(\"Created high_risk_score feature\")\n",
    "\n",
    "# Create glucose level categories\n",
    "df_processed['glucose_level_cat'] = pd.cut(df_processed['avg_glucose_level'],\n",
    "                                           bins=[0, 100, 150, 200, 500],\n",
    "                                           labels=['normal', 'prediabetic', 'diabetic', 'very_high'])\n",
    "print(\"Created glucose_level_cat feature\")\n",
    "\n",
    "# Create BMI categories\n",
    "df_processed['bmi_category'] = pd.cut(df_processed['bmi'],\n",
    "                                      bins=[0, 18.5, 25, 30, 100],\n",
    "                                      labels=['underweight', 'normal', 'overweight', 'obese'])\n",
    "print(\"Created bmi_category feature\")\n",
    "\n",
    "# Create smoking risk\n",
    "df_processed['smoking_risk'] = df_processed['smoking_status'].map({\n",
    "    'never smoked': 0,\n",
    "    'Unknown': 1,\n",
    "    'formerly smoked': 2,\n",
    "    'smokes': 3\n",
    "})\n",
    "print(\"Created smoking_risk feature\")\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e9ef5",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f4e86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CATEGORICAL ENCODING\n",
      "================================================================================\n",
      "Applied binary encoding to gender and ever_married\n",
      "Applied one-hot encoding to categorical features\n",
      "Dropped id and smoking_status columns\n",
      "\n",
      "Final model dataset shape: (57281, 24)\n",
      "Total features: 23\n",
      "\n",
      "Column names:\n",
      "['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'avg_glucose_level', 'bmi', 'stroke', 'high_risk_score', 'smoking_risk', 'work_type_Govt_job', 'work_type_Private', 'work_type_Self-employed', 'Residence_type_Urban', 'age_group_30-40', 'age_group_40-50', 'age_group_50-60', 'age_group_60+', 'glucose_level_cat_prediabetic', 'glucose_level_cat_diabetic', 'glucose_level_cat_very_high', 'bmi_category_normal', 'bmi_category_overweight', 'bmi_category_obese']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORICAL ENCODING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_model = df_processed.copy()\n",
    "\n",
    "# Binary encoding\n",
    "df_model['gender'] = (df_model['gender'] == 'Male').astype(int)\n",
    "df_model['ever_married'] = (df_model['ever_married'] == 'Yes').astype(int)\n",
    "print(\"Applied binary encoding to gender and ever_married\")\n",
    "\n",
    "# One-hot encoding\n",
    "df_model = pd.get_dummies(df_model, \n",
    "                          columns=['work_type', 'Residence_type', 'age_group', \n",
    "                                  'glucose_level_cat', 'bmi_category'], \n",
    "                          drop_first=True)\n",
    "print(\"Applied one-hot encoding to categorical features\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_model = df_model.drop(['id', 'smoking_status'], axis=1)\n",
    "print(\"Dropped id and smoking_status columns\")\n",
    "\n",
    "# Convert boolean to int\n",
    "for col in df_model.columns:\n",
    "    if df_model[col].dtype == 'bool':\n",
    "        df_model[col] = df_model[col].astype(int)\n",
    "\n",
    "print(f\"\\nFinal model dataset shape: {df_model.shape}\")\n",
    "print(f\"Total features: {len(df_model.columns) - 1}\")  # -1 for target\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df_model.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9cb738",
   "metadata": {},
   "source": [
    "## Train-Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e10b9767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN-TEST SPLIT & SCALING\n",
      "================================================================================\n",
      "\n",
      "Train set: 45824 samples (Stroke rate: 16.95%)\n",
      "Test set: 11457 samples (Stroke rate: 16.95%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT & SCALING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X = df_model.drop('stroke', axis=1)\n",
    "y = df_model['stroke']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                      random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples (Stroke rate: {y_train.mean()*100:.2f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples (Stroke rate: {y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b32cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied StandardScaler to features\n",
      "\n",
      "X_train_scaled shape: (45824, 23)\n",
      "X_test_scaled shape: (11457, 23)\n"
     ]
    }
   ],
   "source": [
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"Applied StandardScaler to features\")\n",
    "print(f\"\\nX_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "084399fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights (for handling imbalance):\n",
      "Class 0 (No Stroke): 0.6020\n",
      "Class 1 (Stroke): 2.9503\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights for handling imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(f\"\\nClass weights (for handling imbalance):\")\n",
    "print(f\"Class 0 (No Stroke): {class_weight_dict[0]:.4f}\")\n",
    "print(f\"Class 1 (Stroke): {class_weight_dict[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f0b0923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved processed data files for next notebooks\n"
     ]
    }
   ],
   "source": [
    "# Save processed data for next notebooks\n",
    "X_train_scaled.to_csv(\"../data/X_train_scaled.csv\", index=False)\n",
    "X_test_scaled.to_csv(\"../data/X_test_scaled.csv\", index=False)\n",
    "y_train.to_csv(\"../data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../data/y_test.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved processed data files for next notebooks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
